{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business objective of this task is to optimize the effectiveness of a Portuguese banking institution's direct marketing campaigns. Specifically, the goal is to:\n",
    "\n",
    "Predict Customer Subscription: Build a predictive model to determine whether a client will subscribe to a term deposit (indicated by the target variable $y$).\n",
    "\n",
    "Optimize Marketing Resources: By identifying clients with a high probability of subscribing, the bank can focus its resources (time, staffing, and marketing budget) on the most promising leads, thereby reducing the number of unnecessary or unproductive contacts.\n",
    "\n",
    "Identify Key Success Factors: Analyze client demographics (age, job, education), past campaign outcomes, and socio-economic indicators (employment variation rate, consumer price index) to understand which factors most significantly influence a client's decision to subscribe.\n",
    "\n",
    "Ultimately, this allows the bank to increase its conversion rate for term deposits while maintaining cost-efficient marketing operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n",
      "y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/maniliy07/Module17/refs/heads/main/bank-additional-full.csv\",sep=';')\n",
    "\n",
    "# Inspect the first few rows and summary information\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit Null Counts:\n",
      " age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "\n",
      "'Unknown' Value Counts:\n",
      " age                  0\n",
      "job                330\n",
      "marital             80\n",
      "education         1731\n",
      "default           8597\n",
      "housing            990\n",
      "loan               990\n",
      "contact              0\n",
      "month                0\n",
      "day_of_week          0\n",
      "duration             0\n",
      "campaign             0\n",
      "pdays                0\n",
      "previous             0\n",
      "poutcome             0\n",
      "emp.var.rate         0\n",
      "cons.price.idx       0\n",
      "cons.conf.idx        0\n",
      "euribor3m            0\n",
      "nr.employed          0\n",
      "y                    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "y                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for explicit missing values\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Check for 'unknown' strings which often represent missing data in this specific dataset\n",
    "unknown_counts = (df == 'unknown').sum()\n",
    "\n",
    "# Display data types and unique values for categorical columns to check for coercion needs\n",
    "data_types = df.dtypes\n",
    "categorical_summary = {col: df[col].unique()[:5] for col in df.select_dtypes(include=['object']).columns}\n",
    "\n",
    "print(\"Explicit Null Counts:\\n\", null_counts)\n",
    "print(\"\\n'Unknown' Value Counts:\\n\", unknown_counts)\n",
    "print(\"\\nData Types:\\n\", data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Business Objective of this task is to develop a predictive model that identifies the likelihood of a client subscribing to a term deposit following a direct marketing (telemarketing) campaign.\n",
    "\n",
    "By accurately predicting the outcome ($y$), the bank can achieve the following goals\n",
    "\n",
    ":Increase Campaign Efficiency: Focus marketing efforts and resources on clients with the highest probability of conversion, rather than contacting the entire database.\n",
    "\n",
    "Reduce Operational Costs: Minimize the time and labor costs spent on \"unsuccessful\" calls.\n",
    "\n",
    "Enhance Customer Experience: Reduce \"marketing fatigue\" by avoiding unnecessary contact with customers who have a low propensity to subscribe.\n",
    "\n",
    "Identify Key Drivers: Determine which factors (e.g., economic indicators like the euribor3m rate, or customer demographics like job and education) are the strongest predictors of a successful subscription to inform future product offerings and strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded columns: ['age', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_married', 'marital_single', 'marital_unknown', 'education_basic.6y', 'education_basic.9y', 'education_high.school', 'education_illiterate', 'education_professional.course', 'education_university.degree', 'education_unknown', 'default_unknown', 'default_yes', 'housing_unknown', 'housing_yes', 'loan_unknown', 'loan_yes', 'y']\n",
      "   age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "0   56            False             False           True           False   \n",
      "1   57            False             False          False           False   \n",
      "2   37            False             False          False           False   \n",
      "3   40            False             False          False           False   \n",
      "4   56            False             False          False           False   \n",
      "\n",
      "   job_retired  job_self-employed  job_services  job_student  job_technician  \\\n",
      "0        False              False         False        False           False   \n",
      "1        False              False          True        False           False   \n",
      "2        False              False          True        False           False   \n",
      "3        False              False         False        False           False   \n",
      "4        False              False          True        False           False   \n",
      "\n",
      "   ...  education_professional.course  education_university.degree  \\\n",
      "0  ...                          False                        False   \n",
      "1  ...                          False                        False   \n",
      "2  ...                          False                        False   \n",
      "3  ...                          False                        False   \n",
      "4  ...                          False                        False   \n",
      "\n",
      "   education_unknown  default_unknown  default_yes  housing_unknown  \\\n",
      "0              False            False        False            False   \n",
      "1              False             True        False            False   \n",
      "2              False            False        False            False   \n",
      "3              False            False        False            False   \n",
      "4              False            False        False            False   \n",
      "\n",
      "   housing_yes  loan_unknown  loan_yes  y  \n",
      "0        False         False     False  0  \n",
      "1        False         False     False  0  \n",
      "2         True         False     False  0  \n",
      "3        False         False     False  0  \n",
      "4        False         False      True  0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select the bank information features (1-7) and the target (y)\n",
    "bank_features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "target = 'y'\n",
    "\n",
    "X = df[bank_features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# 1. Encode the target variable (yes -> 1, no -> 0)\n",
    "y = y.map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 2. Encode categorical features\n",
    "# Using get_dummies for job, marital, education, default, housing, loan\n",
    "# This handles the 'unknown' values as distinct categories.\n",
    "X_encoded = pd.get_dummies(X, columns=['job', 'marital', 'education', 'default', 'housing', 'loan'], drop_first=True)\n",
    "\n",
    "# Combine into a single dataframe for the final output\n",
    "processed_df = pd.concat([X_encoded, y], axis=1)\n",
    "\n",
    "# Save the processed data to CSV\n",
    "processed_df.to_csv('processed_bank_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows and column names to confirm\n",
    "print(\"Encoded columns:\", processed_df.columns.tolist())\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (28831, 28)\n",
      "X_test shape: (12357, 28)\n",
      "y_train distribution:\n",
      "y\n",
      "0    0.887343\n",
      "1    0.112657\n",
      "Name: proportion, dtype: float64\n",
      "y_test distribution:\n",
      "y\n",
      "0    0.887351\n",
      "1    0.112649\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  Split features and target\n",
    "X = processed_df.drop(columns=['y'])\n",
    "y = processed_df['y']\n",
    "\n",
    "# Split into train and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Save the sets to CSV\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"y_test distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish a baseline for your classifier, we look at the performance of a Majority Class Classifier (also known as a \"Zero Rule\" model). This model always predicts the most frequent outcome regardless of the input data.\n",
    "\n",
    "\n",
    "Based on the distribution of your training data:\n",
    "\n",
    "\"No\" (Did not subscribe): ~88.73%\n",
    "\n",
    "\"Yes\" (Subscribed): ~11.27%\n",
    "\n",
    "Baseline Accuracy: 88.73%\n",
    "If your model simply predicts \"no\" for every single client, it will be correct approximately 88.73% of the time. This is the score to beat.\n",
    "\n",
    "Why this matters:\n",
    "The Accuracy Trap: Any model that achieves an accuracy lower than or equal to 88.73% is effectively performing no better (or worse) than a model that does not learn anything from the features.\n",
    "\n",
    "Beyond Accuracy: Because the dataset is imbalanced (only ~11% subscribed), accuracy alone is not a sufficient metric. While the baseline accuracy is high, the baseline Recall for the \"yes\" class is 0%. A useful business model must aim to beat the 88.7% accuracy while specifically maximizing the identification of the \"yes\" subscribers through metrics like F1-Score, Precision, and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the split data\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "# Increased max_iter to ensure convergence\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8874\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     10965\n",
      "           1       0.00      0.00      0.00      1392\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.44      0.50      0.47     12357\n",
      "weighted avg       0.79      0.89      0.83     12357\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10965     0]\n",
      " [ 1392     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\test\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\test\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\test\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression    0.054186        0.887343       0.887351\n",
      "1                  KNN    0.010412        0.890569       0.878530\n",
      "2        Decision Tree    0.117302        0.918837       0.864045\n",
      "3                  SVM   42.061559        0.887448       0.887432\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Time': train_time,\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Save to CSV for the user\n",
    "results_df.to_csv('model_performance_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To move beyond default settings and improve model performance, we can implement Hyperparameter Tuning using GridSearchCV. This process systematically searches through a range of values to find the combination that maximizes your chosen performance metric.\n",
    "\n",
    "Since this is a classification task (predicting whether a customer will subscribe), accuracy might be misleading if the classes are imbalanced. We should consider metrics like Precision, Recall, or F1-score.\n",
    "\n",
    "Here is how we can structure the improvement phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Example for Decision Tree\n",
    "dt_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('dtree', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'dtree__max_depth': [3, 5, 10, None],\n",
    "    'dtree__min_samples_split': [2, 5, 10],\n",
    "    'dtree__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(dt_pipe, param_grid, cv=5, scoring='f1') # Tuning for F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
